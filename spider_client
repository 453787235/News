# --*--coding:utf-8 --*--
__author__ = 'Administrator'

from lxml import etree
import threadpool
import util
import json

headers={
	'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
	'Accept-Encoding':'gzip, deflate, sdch',
	'Accept-Language':'zh-CN,zh;q=0.8',
	'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',
	'Host':'insurance.hexun.com',
	}
ns = util.News(headers)
redis = util.RedisUtils()

def spider(urls):
	link = {}
	req = ns.Requests(urls,headers)
	res = etree.HTML(req.content)
	all_urls = ns.geturl(res,'//div[@class="temp01"]/ul/li/a/@href')
	link['urls'] = all_urls
	redis.rpush('urls',json.dumps(link))

if __name__ == '__main__':
	urls = [
	'http://insurance.hexun.com/bxhyzx/index.html',
	'http://insurance.hexun.com/bxgsxw/index.html',
	'http://insurance.hexun.com/bxzjyy/index.html',
	'http://insurance.hexun.com/bxscpl/',
	'http://insurance.hexun.com/2007/bxpdzt/index.html',
	]
	pool = threadpool.ThreadPool(10)
	requests = threadpool.makeRequests(spider, urls)
	[pool.putRequest(req) for req in requests]
	pool.wait()
